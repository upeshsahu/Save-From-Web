#Save From Web

Getting Bored by opening the GEEKSFORGEEKS for dijstra for 1000 thousand .here is the solution.
this is abasic Command line tool that will help you to save important web Pages(images too :) ) in pdf format. 



<h1>Requirements</h1>
<ul>
  <li>Python 3.x</li>
  <li>Selenium</li>
  <li>wkhtmltopdf</li>
  <li>pdfkit</li>
  <li>Phantomjs</li>
</ul>

<h1>Getting Started</h1>
<ul>
    <li>Clone the repository and unzip the zip or tarball.</li>
    <li>Download Latest version of Python (3.x) <a href="https://www.python.org/downloads/"> Link </a> </li>
    <li>Install Selenium<a href="https://selenium-python.readthedocs.io/installation.html">Link</a></li>
   <li>Install wkhtml <a href="https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf">Link</a> </li>
    <li>Install Phantomjs<a href="https://www.vultr.com/docs/how-to-install-phantomjs-on-ubuntu-16-04">Link</a></li>
</ul>

<h1>How to Use</h1>
<ul>
  <li> Open location of Downloaded folder - <b>Run python3 save_from_web.py</b> in the Terminal </li>
  <li>copy the url of webpage and paste it in terminal</li>
<h1>Contribute</h1>
<ul>
  <li>Feel free to report issues , it just a simple web scrapper , multiple features can be added </li>
<li>All Suggestions are welcome . </li>
<li>Fork repository and Contribute. </li>
</ul>



